# AI-Based Student Performance Prediction System

A professional ML project using an end-to-end pipeline architecture to predict student performance.

---

## ğŸ“‚ Project Structure

```text
student_performance_project/
â”‚
â”œâ”€â”€ artifacts/           # Trained models and preprocessor objects
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”‚
â”œâ”€â”€ Data/                # Raw dataset
â”‚   â””â”€â”€ students_data.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/      # Pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/        # Orchestration pipelines
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â””â”€â”€ predict_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logger.py        # Logging system
â”‚   â”œâ”€â”€ exception.py     # Custom exception handling
â”‚   â””â”€â”€ utils.py         # Utility functions
â”‚
â”œâ”€â”€ templates/           # Flask HTML templates
â”œâ”€â”€ static/              # CSS/Static files
â”œâ”€â”€ app.py               # Flask application entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Setup & Installation

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Train the Pipeline**
   ```bash
   # Generates models and preprocessor in artifacts/
   python -m src.pipeline.train_pipeline
   ```

3. **Run the Web App**
   ```bash
   # Start the Flask portal
   python app.py
   ```

---

## ğŸš€ AI Pipeline Workflow

```mermaid
graph TD
    A[ğŸ“‚ Raw Data] -->|Ingest| B(âš™ï¸ Data Ingestion)
    B -->|Split| C(ğŸ› ï¸ Data Transformation)
    C -->|Train| D{ğŸ“ Model Trainer}
    D -->|Evaluate & Save| E[ğŸ’¾ Best Model & Preprocessor]
    
    E --> F[ğŸŒ Flask Web Application]
    F -->|Inference| G[ğŸ“Š Prediction Result]
```

### Pipeline Components:
1.  **Data Ingestion**: Reads raw CSV data, creates artifacts folder, and performs train-test split.
2.  **Data Transformation**: Handles missing values and scales features using a professional `ColumnTransformer` and `Pipeline`.
3.  **Model Trainer**: Automatically trains multiple models (Random Forest, Logistic Regression, etc.) and picks the best-performing one.
4.  **Prediction Pipeline**: A standalone module that takes user input, applies the trained transformations, and returns a prediction.

---

## ğŸ› ï¸ Features
- **Standardized Logging**: Every step of the pipeline is logged for debugging.
- **Custom Error Handling**: Detailed error messages including file names and line numbers.
- **Automated Preprocessing**: Uses robust sklearn pipelines for numerical scaling.
- **Model Selection**: Automatically selects the best machine learning model based on accuracy.